{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis - `keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import nibabel as nb\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from keras import layers, models, optimizers, regularizers\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dataset(filename, outlier_thr=5):\n",
    "\n",
    "    # Read csv file\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # extract relevant variables\n",
    "    sub_id = np.array(df['PAC_ID'])\n",
    "    label = np.array(df['Label'] - 1)\n",
    "    df = df.drop(['PAC_ID', 'Label'], 1)\n",
    "    header = df.keys()\n",
    "    \n",
    "    # Clean dataset - drop subjects with values above `outlier_thr` STD\n",
    "    outliers = np.sum((np.abs(zscore(df)) > outlier_thr), 1) != 0\n",
    "    print('%d outliers detected.' % outliers.sum())\n",
    "    data = np.array(df.drop(np.where(outliers)[0]))\n",
    "    sub_id = sub_id[np.invert(outliers)]\n",
    "    label = label[np.invert(outliers)]\n",
    "    \n",
    "    # zscore data\n",
    "    data = zscore(data)\n",
    "\n",
    "    # Reset Gender and Scanner values to nominal values\n",
    "    data[:,1] = (data[:,1]>0) + 1\n",
    "    data[:,3] = [np.where(i==np.unique(data[:,3]))[0][0] + 1for i in data[:,3]]\n",
    "\n",
    "    return pd.DataFrame(data, columns=header), sub_id, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 outliers detected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>TIV</th>\n",
       "      <th>Scanner</th>\n",
       "      <th>Tvoxels</th>\n",
       "      <th>Tmean</th>\n",
       "      <th>Tmedian</th>\n",
       "      <th>Tstd</th>\n",
       "      <th>Tmax</th>\n",
       "      <th>Left_Frontal_Pole</th>\n",
       "      <th>...</th>\n",
       "      <th>Right_Cerebral_White_Matter</th>\n",
       "      <th>Right_Cerebral_Cortex</th>\n",
       "      <th>Right_Lateral_Ventricle</th>\n",
       "      <th>Right_Thalamus</th>\n",
       "      <th>Right_Caudate</th>\n",
       "      <th>Right_Putamen</th>\n",
       "      <th>Right_Pallidum</th>\n",
       "      <th>Right_Hippocampus</th>\n",
       "      <th>Right_Amygdala</th>\n",
       "      <th>Right_Accumbens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.610405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.479924</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.890455</td>\n",
       "      <td>1.091014</td>\n",
       "      <td>1.080367</td>\n",
       "      <td>1.034026</td>\n",
       "      <td>0.060878</td>\n",
       "      <td>1.096927</td>\n",
       "      <td>...</td>\n",
       "      <td>1.093750</td>\n",
       "      <td>1.094903</td>\n",
       "      <td>1.037705</td>\n",
       "      <td>-0.896948</td>\n",
       "      <td>-0.255150</td>\n",
       "      <td>-0.724690</td>\n",
       "      <td>-0.269052</td>\n",
       "      <td>1.791264</td>\n",
       "      <td>1.591691</td>\n",
       "      <td>0.091529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.146076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.052883</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.134709</td>\n",
       "      <td>-0.118805</td>\n",
       "      <td>-0.147065</td>\n",
       "      <td>0.290905</td>\n",
       "      <td>0.904814</td>\n",
       "      <td>0.017488</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060199</td>\n",
       "      <td>-0.013714</td>\n",
       "      <td>0.079673</td>\n",
       "      <td>0.634875</td>\n",
       "      <td>1.097503</td>\n",
       "      <td>0.176912</td>\n",
       "      <td>-0.143525</td>\n",
       "      <td>0.223282</td>\n",
       "      <td>0.283818</td>\n",
       "      <td>-0.110870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.200997</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.322187</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.910314</td>\n",
       "      <td>0.213228</td>\n",
       "      <td>0.466651</td>\n",
       "      <td>-0.390523</td>\n",
       "      <td>0.488056</td>\n",
       "      <td>-0.281768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167886</td>\n",
       "      <td>0.162364</td>\n",
       "      <td>0.443724</td>\n",
       "      <td>0.107536</td>\n",
       "      <td>-0.337023</td>\n",
       "      <td>-0.458773</td>\n",
       "      <td>-0.199329</td>\n",
       "      <td>0.879846</td>\n",
       "      <td>0.603997</td>\n",
       "      <td>0.182364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.200997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.526994</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.888128</td>\n",
       "      <td>1.178024</td>\n",
       "      <td>1.141739</td>\n",
       "      <td>1.173458</td>\n",
       "      <td>0.863138</td>\n",
       "      <td>0.754654</td>\n",
       "      <td>...</td>\n",
       "      <td>1.022908</td>\n",
       "      <td>1.000870</td>\n",
       "      <td>2.157792</td>\n",
       "      <td>1.573471</td>\n",
       "      <td>2.835140</td>\n",
       "      <td>1.080137</td>\n",
       "      <td>0.815276</td>\n",
       "      <td>0.185643</td>\n",
       "      <td>0.730864</td>\n",
       "      <td>2.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.004188</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.934370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.027570</td>\n",
       "      <td>-2.074238</td>\n",
       "      <td>-2.049584</td>\n",
       "      <td>-2.070608</td>\n",
       "      <td>-0.824733</td>\n",
       "      <td>-2.118870</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.148225</td>\n",
       "      <td>-2.165083</td>\n",
       "      <td>-1.193547</td>\n",
       "      <td>-1.593558</td>\n",
       "      <td>-2.270355</td>\n",
       "      <td>-1.290505</td>\n",
       "      <td>-1.337832</td>\n",
       "      <td>-1.919742</td>\n",
       "      <td>-2.127827</td>\n",
       "      <td>-1.856324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Gender       TIV  Scanner   Tvoxels     Tmean   Tmedian  \\\n",
       "0  1.610405     1.0  1.479924      2.0 -0.890455  1.091014  1.080367   \n",
       "1 -1.146076     1.0 -0.052883      1.0  1.134709 -0.118805 -0.147065   \n",
       "2 -0.200997     2.0 -0.322187      2.0 -0.910314  0.213228  0.466651   \n",
       "3 -0.200997     1.0  1.526994      3.0 -0.888128  1.178024  1.141739   \n",
       "4  2.004188     2.0 -0.934370      1.0  1.027570 -2.074238 -2.049584   \n",
       "\n",
       "       Tstd      Tmax  Left_Frontal_Pole       ...         \\\n",
       "0  1.034026  0.060878           1.096927       ...          \n",
       "1  0.290905  0.904814           0.017488       ...          \n",
       "2 -0.390523  0.488056          -0.281768       ...          \n",
       "3  1.173458  0.863138           0.754654       ...          \n",
       "4 -2.070608 -0.824733          -2.118870       ...          \n",
       "\n",
       "   Right_Cerebral_White_Matter  Right_Cerebral_Cortex  \\\n",
       "0                     1.093750               1.094903   \n",
       "1                    -0.060199              -0.013714   \n",
       "2                     0.167886               0.162364   \n",
       "3                     1.022908               1.000870   \n",
       "4                    -2.148225              -2.165083   \n",
       "\n",
       "   Right_Lateral_Ventricle  Right_Thalamus  Right_Caudate  Right_Putamen  \\\n",
       "0                 1.037705       -0.896948      -0.255150      -0.724690   \n",
       "1                 0.079673        0.634875       1.097503       0.176912   \n",
       "2                 0.443724        0.107536      -0.337023      -0.458773   \n",
       "3                 2.157792        1.573471       2.835140       1.080137   \n",
       "4                -1.193547       -1.593558      -2.270355      -1.290505   \n",
       "\n",
       "   Right_Pallidum  Right_Hippocampus  Right_Amygdala  Right_Accumbens  \n",
       "0       -0.269052           1.791264        1.591691         0.091529  \n",
       "1       -0.143525           0.223282        0.283818        -0.110870  \n",
       "2       -0.199329           0.879846        0.603997         0.182364  \n",
       "3        0.815276           0.185643        0.730864         2.010200  \n",
       "4       -1.337832          -1.919742       -2.127827        -1.856324  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, sub_id, label = read_dataset('data/PAC2018_Covariates_detailed.csv', outlier_thr=5)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset (select dataset, balance it and divide train and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def balance_dataset(sub_id, labels, data):\n",
    "    max_label_size = np.min([np.sum(lab == labels) \n",
    "                             for lab in np.unique(labels)])\n",
    "\n",
    "    labels_1 = np.where(labels == 0)[0]\n",
    "    np.random.shuffle(labels_1)\n",
    "    labels_1 = labels_1[:max_label_size]\n",
    "\n",
    "    labels_2 = np.where(labels == 1)[0]\n",
    "    np.random.shuffle(labels_2)\n",
    "    labels_2 = labels_2[:max_label_size]\n",
    "\n",
    "    new_data_id = np.hstack((labels_1, labels_2))\n",
    "    np.random.shuffle(new_data_id)\n",
    "    labels = labels[new_data_id]\n",
    "    sub_id = sub_id[new_data_id]\n",
    "    data = data[new_data_id]\n",
    "\n",
    "    return (sub_id, labels, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_valid_set(sub_id, label, data, group='123', train_ratio=0.8):\n",
    "    \n",
    "    selecter = [str(int(d)) in group for d in data.Scanner]\n",
    "\n",
    "    group_sub, group_label, group_data = balance_dataset(\n",
    "        sub_id[selecter], label[selecter], np.array(data[selecter]))\n",
    "    \n",
    "    \n",
    "    train_size = int(len(group_sub) * train_ratio)\n",
    "    valid_size = len(group_sub) - train_size\n",
    "\n",
    "    counter1 = 0\n",
    "    counter2 = 0\n",
    "    train_list = []\n",
    "\n",
    "    for i, s in enumerate(group_sub):\n",
    "        if counter1 < (train_size / 2) and group_label[i] == 0:\n",
    "            train_list.append(s)\n",
    "            counter1 += 1\n",
    "        elif counter2 < (train_size / 2) and group_label[i] == 1:\n",
    "            train_list.append(s)\n",
    "            counter2 += 1\n",
    "\n",
    "    selecter = np.array([True if e in train_list else False for i, e in enumerate(group_sub)])\n",
    "\n",
    "    train_list = group_sub[selecter]\n",
    "    valid_list = group_sub[np.invert(selecter)]\n",
    "    \n",
    "    return train_list, valid_list, group_sub, group_label, group_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Keras` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_gen(fileList, batch):\n",
    "\n",
    "    while True:\n",
    "        for r in range(0, len(fileList), batch):\n",
    "\n",
    "            batch_data = []\n",
    "            batch_label = []\n",
    "\n",
    "            for i in range(batch):\n",
    "                if r + i >= len(fileList):\n",
    "                    break\n",
    "                else:\n",
    "\n",
    "                    patientID = fileList[r]\n",
    "                    f = 'data/nifti/%s.nii.gz' % patientID\n",
    "\n",
    "                    # Get data for each subject\n",
    "                    img = nb.load(f).get_fdata()\n",
    "                    img = img[15:105, 15:125, 15:100]\n",
    "\n",
    "                    batch_data.append(img)\n",
    "\n",
    "                    # Get data for each label\n",
    "                    labelID = group_label[group_sub == patientID]\n",
    "                    batch_label.append(labelID)\n",
    "\n",
    "            yield (np.array(batch_data)[..., None], np.array(batch_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_26 (Conv3D)           (None, 88, 108, 83, 32)   896       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_22 (MaxPooling (None, 29, 36, 27, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_27 (Conv3D)           (None, 27, 34, 25, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_23 (MaxPooling (None, 9, 11, 8, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_28 (Conv3D)           (None, 8, 10, 7, 32)      8224      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_24 (MaxPooling (None, 4, 5, 3, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_29 (Conv3D)           (None, 3, 4, 2, 32)       8224      \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                12304     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 57,345\n",
      "Trainable params: 57,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Neural network definition\n",
    "model = models.Sequential()\n",
    "\n",
    "input_shape = (90, 110, 85, 1)\n",
    "\n",
    "model.add(layers.Conv3D(32, kernel_size=(3, 3, 3), activation='relu', strides=(1, 1, 1),\n",
    "                        input_shape=input_shape, batch_size=None))\n",
    "model.add(layers.MaxPooling3D(pool_size=(3, 3, 3)))\n",
    "\n",
    "model.add(layers.Conv3D(32, kernel_size=(3, 3, 3), activation='relu', strides=(1, 1, 1)))\n",
    "model.add(layers.MaxPooling3D(pool_size=(3, 3, 3)))\n",
    "\n",
    "model.add(layers.Conv3D(32, kernel_size=(2, 2, 2), activation='relu', strides=(1, 1, 1)))\n",
    "model.add(layers.MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model.add(layers.Conv3D(32, kernel_size=(2, 2, 2), activation='relu', strides=(1, 1, 1)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch_size = 1\n",
    "\n",
    "# Training to Validation set ratio\n",
    "train_ratio=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Groups\n",
    "group_id = '23'\n",
    "train_list, valid_list, group_sub, group_label, group_data = get_train_valid_set(\n",
    "    sub_id, label, data, group=group_id, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 34/710 [>.............................] - ETA: 1:12:53 - loss: 0.6904 - binary_accuracy: 0.5882"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    data_gen(train_list, batch_size),\n",
    "    steps_per_epoch=int(np.ceil(len(train_list) / batch_size)),\n",
    "    validation_data=data_gen(valid_list, batch_size),\n",
    "    validation_steps=int(np.ceil(len(valid_list) / batch_size)),\n",
    "    epochs=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "plt.plot(history.history['binary_accuracy'], label='Training accuracy')\n",
    "plt.plot(history.history['val_binary_accuracy'], label='Testing accuracy')\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Testing Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc=4)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
